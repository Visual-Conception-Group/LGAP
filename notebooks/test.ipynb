{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader,Dataset, ConcatDataset, Subset\n",
    "# import torchsummary\n",
    "import torchattacks\n",
    "from autoattack import AutoAttack\n",
    "import timm\n",
    " \n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import robustbench\n",
    "from robustbench.data import load_cifar10, load_imagenet\n",
    "from robustbench.utils import load_model, clean_accuracy\n",
    "from scripts.custom_Dataset import CustomDataset\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([transforms.ToTensor(),])\n",
    "                                # transforms.Resize((224,224))])\n",
    "                                # transforms.Resize((96,96)),\n",
    "                    #   normalize])\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "batch_size = 512\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset_indices = list(range(1500))\n",
    "# batch_size = 512\n",
    "# # image_folder = \"../BLIP/experiment_1/stl_10/clean_test_images/\"\n",
    "# image_folder_1 = \"../BLIP/experiment_1/stl_10/clean_train_images/\"\n",
    "# # label_file = '../BLIP/experiment_1/stl_10/clean_test_labels.txt'\n",
    "# label_file_1 = \"../BLIP/experiment_1/stl_10/clean_train_labels.txt\"\n",
    "\n",
    "# image_folder_2 = \"../BLIP/experiment_1/stl_10/clean_train_generated/resized/\"\n",
    "# # label_file = '../BLIP/experiment_1/stl_10/clean_test_labels.txt'\n",
    "# label_file_2 = \"../BLIP/experiment_1/stl_10/clean_train_labels.txt\"\n",
    "# image_folder_3 = \"../BLIP/experiment_1/stl_10/adv_test_generated_e2e/samples/\"\n",
    "# label_file_3 = \"../BLIP/experiment_1/stl_10/adv_test_labels.txt\"\n",
    "\n",
    "# train_dataset_1 = CustomDataset(image_folder_1, label_file_1, transform=transform)\n",
    "# train_dataset_2 = CustomDataset(image_folder_2, label_file_2, transform=transform)\n",
    "# combined_dataset = ConcatDataset([train_dataset_1, train_dataset_2])\n",
    "# train_loader = torch.utils.data.DataLoader(combined_dataset, batch_size=batch_size,\n",
    "#                                      shuffle=True)\n",
    "# test_dataset = CustomDataset(image_folder_3, label_file_3, transform=transform)\n",
    "# subset = Subset(test_dataset, subset_indices)\n",
    "# test_loader = torch.utils.data.DataLoader(subset, batch_size=batch_size,\n",
    "#                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '../BLIP/experiment_1/cifar10/adv_test_generated_aa/'\n",
    "label_file = '../BLIP/experiment_1/cifar10/clean_test_labels.txt'\n",
    "# image_folder = '../BLIP/experiment_1/imagenet/clean_test_2048/'\n",
    "# label_file = '../BLIP/experiment_1/imagenet/clean_test_labels_2048.txt'\n",
    "# image_folder = '../BLIP/experiment_1/cifar10/clean_test_generated/'\n",
    "# label_file = '../BLIP/experiment_1/cifar10/clean_test_labels.txt'\n",
    "# # captions_file = \"../BLIP/experiment_1/stl_10/clean_test_captions.txt\"\n",
    "test_dataset = CustomDataset(image_folder, label_file, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet50(pretrained=True)\n",
    "# model = load_model(model_name='Standard', dataset='cifar10', threat_model='Linf').eval()\n",
    "# model = load_model(model_name='Standard_R50', dataset='imagenet', threat_model='Linf')\n",
    "# model = models.resnet50(pretrained=True).eval()\n",
    "# model = models.wide_resnet50_2(pretrained=True).eval()\n",
    "model = torch.load(\"wrn28_10_cifar10_trained_on_diffusion_images_only.pth\").module.eval()\n",
    "# model = timm.create_model('wide_resnet50_2', pretrained=True).eval()\n",
    "model = nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_list = []\n",
    "labels_list = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images_list.append(images)\n",
    "    labels_list.append(labels)\n",
    "\n",
    "# Concatenate all batches\n",
    "x_test = torch.cat(images_list, 0)\n",
    "y_test = torch.cat(labels_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1777\n"
     ]
    }
   ],
   "source": [
    "acc = clean_accuracy(model, x_test, y_test, device=device, batch_size=512)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(test_loader)\n",
    "x,y = next(i)\n",
    "\n",
    "# mean = [0.48145466, 0.4578275, 0.40821073]\n",
    "# std = [0.26862954, 0.26130258, 0.27577711]\n",
    "# def inverse_normalize(batch_tensor, mean=mean, std=std):\n",
    "#     for tensor, m, s in zip(batch_tensor, mean, std):\n",
    "#         tensor.mul_(s).add_(m)\n",
    "#     return batch_tensor\n",
    "# blip_normalize = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "# transform_blip = transforms.Compose([transforms.Resize(size=(384,384)),\n",
    "#                                 blip_normalize\n",
    "#                                 ])\n",
    "# resize = transforms.Compose([transforms.Resize(size=(32,32))])\n",
    "# init_image = transform_blip(x)\n",
    "# init_image = inverse_normalize(init_image)\n",
    "# init_image = resize(init_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_folder = '../BLIP/experiment_1/cifar10/test'\n",
    "# count = 0\n",
    "# for a_i in x_test.cpu():\n",
    "#     save_image(a_i, \"../BLIP/experiment_1/imagenet/clean_test_2048/{}.png\".format(count))\n",
    "#     count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageNet(root=\"../data/\", split=\"val\", transform=imagenet_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(test_loader.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_imagenet(5000, data_dir=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = d[0].cuda(), d[1].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = \"../BLIP/experiment_1/imagenet/clean_test_labels_2048.txt\"\n",
    "\n",
    "# Opening the given file in write mode\n",
    "with open(inputFile, 'w') as filedata:\n",
    "\n",
    "   # Traverse in each element of the input list \n",
    "   for item in y_test.cpu():\n",
    "   \n",
    "      # Writing each element of the list into the file\n",
    "      # Here “%s\\n” % syntax is used to move to the next line after adding an item to the file.\n",
    "        filedata.write(\"%s\\n\" % item.numpy().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.767578125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model('wide_resnet50_2', pretrained=True).cuda().eval()\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = AutoAttack(model, norm='Linf', eps=8/255, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary.apgd.n_restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(model(x.cuda()), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldmblip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
